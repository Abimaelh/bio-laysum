# -*- coding: utf-8 -*-
"""Copy of Summarization_Llama3-8b.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BUWcrfWzM0ksbKF4fjTt1qZ2qGQaOA4B
"""

!nvidia-smi

from huggingface_hub import notebook_login

notebook_login()

from google.colab import drive
drive.mount('/content/drive')
import json

import transformers

import torch

model_id = "meta-llama/Llama-3.1-8B-Instruct"

pipeline = transformers.pipeline("text-generation", model=model_id, model_kwargs={"torch_dtype": torch.bfloat16}, device_map="auto")


messages = [
    {"role": "system", "content": "You are a chatbot with expertise in summarizing documents"},
    {"role": "user", "content": "Provide a lay summary of this abstract: Metabolic reprogramming enables tumour cells to sustain their continuous proliferation and adapt to the ever-changing microenvironment. Branched-chain amino acids (BCAAs) and their metabolites are involved in intracellular protein synthesis and catabolism, signal transduction, epigenetic modifications, and the maintenance of oxidative homeostasis. Alterations in BCAA metabolism can influence the progression of various tumours. However, how BCAA metabolism is dysregulated differs among depending on tumour type; for example, it can manifest as decreased BCAA metabolism leading to BCAA accumulation, or as enhanced BCAA uptake and increased catabolism. In this review, we describe the role of BCAA metabolism in the progression of different tumours. As well as discuss how BCAA metabolic reprogramming drives tumour therapy resistance and evasion of the antitumour immune response, and how these pro-cancer effects are achieved in part by activating the mTORC signalling pathway. In-depth investigations into the potential mechanisms by which BCAA metabolic reprogramming affects tumorigenesis and tumour progression can enhance our understanding of the relationship between metabolism and cancer and provide new strategies for cancer therapy."},
]

outputs = pipeline(
    messages,
    max_new_tokens=256,
)
print(outputs[0]["generated_text"][-1])



from transformers import AutoTokenizer
import numpy as np

def truncate_to_token_limit(article, token_limit):

    # Initialize tokenizer
    tokenizer = AutoTokenizer.from_pretrained(model_id)

    # Tokenize the text
    tokens = tokenizer.encode(article)
    # Check if truncation is needed
    if len(tokens) <= token_limit:
        return article

    # If truncation is needed, keep only the first 'token_limit' tokens
    truncated_tokens = tokens[:token_limit]

    # Convert back to text
    truncated_text = tokenizer.decode(truncated_tokens, skip_special_tokens=True)

    return truncated_text

def summarize(pipeline, all_data):
  all_predicted_and_gold = []
  for data in all_data:

    gold_summary=data['gold_summary']
    article = data['preprocessed article']
    truncated_article = truncate_to_token_limit(article, token_limit=4096)
    messages = [
      {"role": "system", "content": "You are a chatbot with expertise in summarizing documents"},
      {"role": "user", "content": f'Provide a lay summary of this abstract: {truncated_article}'},
    ]

    outputs = pipeline(
        messages,

        max_new_tokens=256,
    )
    predicted_summary = outputs[0]["generated_text"][-1]
    print(predicted_summary)
    all_predicted_and_gold.append({'predicted_summary': predicted_summary, 'gold_summary': gold_summary})
  return all_predicted_and_gold

if __name__ == "__main__":
  configuration = 'svd_top40'
  repo = f"/content/drive/MyDrive/biolaysumm/processed_data/processed_data_{configuration}.json"
  output_repo = f"/content/drive/MyDrive/biolaysumm/generated_summaries_preprocessed_{configuration}.json"

  with open(repo, "r") as f:
    data = json.load(f)

  all_predicted_and_gold = summarize(pipeline, data)
  with open(output_repo, "w") as f:
    json.dump(all_predicted_and_gold, f)

"""Instructions on how to prompt engineer by using llama3:
https://colab.research.google.com/github/amitsangani/Llama/blob/main/Llama_3_Prompt_Engineering.ipynb/#scrollTo=aYeHVVh45bdT
"""





